{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27daeffe",
   "metadata": {},
   "source": [
    "# Year column embedding\n",
    "    1. Year column embedding code to preserve time series properties.\n",
    "    2. stock별 시계열패턴을 모델이 학습할수 있도록 작성된 코드."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c78db9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "model = XGBRegressor(enable_categorical=True, tree_method = \"hist\", device = \"cuda\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab950b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target_columns\n",
    "target_columns = ['CETR', 'GETR', 'TSTA', 'TSDA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b75917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV file\n",
    "df = pd.read_csv('data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35926dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set categorical_cols\n",
    "categorical_cols = ['name', 'stock', 'KOSPI', 'big4', 'LOSS', 'ind']\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da361434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target column\n",
    "## drop 'object' dtype\n",
    "X = df.drop(columns=['name'] + target_columns, axis=1)\n",
    "y = df[target_columns]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c15d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-series aware encoding & global cutoff split (2011~2023 train, 2024 test)\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "# 1. Year 기반 전역/종목별 트렌드 & 주기 인코딩\n",
    "year_min = df['year'].min()\n",
    "year_max = df['year'].max()\n",
    "\n",
    "# 전역 정규화 (0~1)\n",
    "df['year_norm_global'] = (df['year'] - year_min) / (year_max - year_min)\n",
    "\n",
    "# 종목별 시작 기준 index (0부터 증가)\n",
    "df['year_index_stock'] = df.groupby('stock')['year'].rank(method='dense').astype(int) - 1\n",
    "# 종목별 상대적 진행도 (0~1)\n",
    "df['year_norm_stock'] = df['year_index_stock'] / df.groupby('stock')['year_index_stock'].transform('max')\n",
    "\n",
    "# 주기성 (사이클) 표현: 한 전체 구간(2011~2024)을 하나의 2π 주기로 가정\n",
    "angle = 2 * np.pi * df['year_norm_global']\n",
    "df['year_sin'] = np.sin(angle)\n",
    "df['year_cos'] = np.cos(angle)\n",
    "\n",
    "# 2. Lag 특징 (1-step lag) 생성: 수치형 컬럼 대상으로 종목별 shift(1)\n",
    "exclude_for_lag = set(['name', 'stock', 'year'] + target_columns)\n",
    "num_cols_for_lag = [c for c in df.columns if c not in exclude_for_lag and df[c].dtype.kind in ['i','u','f']]\n",
    "for col in num_cols_for_lag:\n",
    "    df[f'{col}_lag1'] = df.groupby('stock')[col].shift(1)\n",
    "\n",
    "# 3. 전역 컷오프 기반 연도 분리 (Train: <=2023, Test: 2024)\n",
    "CUTOFF_TEST_YEAR = 2024\n",
    "train_mask = df['year'] < CUTOFF_TEST_YEAR\n",
    "full_test_mask = df['year'] == CUTOFF_TEST_YEAR\n",
    "\n",
    "train_df = df[train_mask].copy()\n",
    "test_full_df = df[full_test_mask].copy()\n",
    "\n",
    "# 4. Seen / New stock 분리 (2024에 대해 과거 데이터 유무)\n",
    "seen_stocks = set(train_df['stock'].unique())\n",
    "seen_test_df = test_full_df[test_full_df['stock'].isin(seen_stocks)].copy()\n",
    "new_test_df = test_full_df[~test_full_df['stock'].isin(seen_stocks)].copy()  # optional 평가용\n",
    "\n",
    "# 5. 특징/타겟 분리 함수\n",
    "def split_Xy(dataframe):\n",
    "    X_ = dataframe.drop(columns=['name', 'stock'] + target_columns)\n",
    "    y_ = dataframe[target_columns]\n",
    "    return X_, y_\n",
    "\n",
    "X_train, y_train = split_Xy(train_df)\n",
    "X_test_seen, y_test_seen = split_Xy(seen_test_df)\n",
    "if len(new_test_df):\n",
    "    X_test_new, y_test_new = split_Xy(new_test_df)\n",
    "else:\n",
    "    X_test_new = y_test_new = None\n",
    "\n",
    "# 6. Lag 결측 처리 (lag1 최초 연도 NaN 등) - 학습셋 중앙값 기준\n",
    "lag_cols = [c for c in X_train.columns if c.endswith('_lag1')]\n",
    "if lag_cols:\n",
    "    lag_medians = X_train[lag_cols].median()\n",
    "    X_train[lag_cols] = X_train[lag_cols].fillna(lag_medians)\n",
    "    X_test_seen[lag_cols] = X_test_seen[lag_cols].fillna(lag_medians)\n",
    "    if X_test_new is not None:\n",
    "        X_test_new[lag_cols] = X_test_new[lag_cols].fillna(lag_medians)\n",
    "\n",
    "print(f\"Train years: {int(train_df['year'].min())}-{int(train_df['year'].max())} | Test year: {CUTOFF_TEST_YEAR}\")\n",
    "print(f\"Seen stocks count: {len(seen_stocks)} | New test stocks count: {len(new_test_df['stock'].unique()) if len(new_test_df) else 0}\")\n",
    "print(\"Shapes -> Train:\", X_train.shape, \"SeenTest:\", X_test_seen.shape, \"NewTest:\", 'None' if X_test_new is None else X_test_new.shape)\n",
    "print(\"Lag feature count:\", len(lag_cols))\n",
    "print(\"Sample feature cols:\", X_train.columns[:10].tolist())\n",
    "\n",
    "# 7. 모델 학습 & 평가\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred_seen = model.predict(X_test_seen)\n",
    "print('[Seen Stocks 2024] R2:', r2_score(y_test_seen, pred_seen),\n",
    "      'MAE:', mean_absolute_error(y_test_seen, pred_seen),\n",
    "      'RMSE:', root_mean_squared_error(y_test_seen, pred_seen))\n",
    "\n",
    "if X_test_new is not None and len(X_test_new):\n",
    "    pred_new = model.predict(X_test_new)\n",
    "    print('[New Stocks 2024] R2:', r2_score(y_test_new, pred_new),\n",
    "          'MAE:', mean_absolute_error(y_test_new, pred_new),\n",
    "          'RMSE:', root_mean_squared_error(y_test_new, pred_new))\n",
    "else:\n",
    "    print('No new (unseen) stocks present in 2024 test set.')\n",
    "\n",
    "# 8. 결과 저장 (Seen test 기준)\n",
    "import numpy as np\n",
    "results_df = pd.DataFrame(\n",
    "    data = np.hstack([y_test_seen.values, pred_seen]),\n",
    "    columns = [f'actual_{col}' for col in y_test_seen.columns] + [f'pred_{col}' for col in y_test_seen.columns],\n",
    "    index = y_test_seen.index\n",
    ")\n",
    "results_df.to_csv('actual_vs_predicted_seen_2024.csv', index=True)\n",
    "if X_test_new is not None and len(X_test_new):\n",
    "    results_new_df = pd.DataFrame(\n",
    "        data = np.hstack([y_test_new.values, pred_new]),\n",
    "        columns = [f'actual_{col}' for col in y_test_new.columns] + [f'pred_{col}' for col in y_test_new.columns],\n",
    "        index = y_test_new.index\n",
    "    )\n",
    "    results_new_df.to_csv('actual_vs_predicted_newStocks_2024.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89822e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ed8469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics and scoring\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "actuals = y_test\n",
    "\n",
    "# Save actual and predicted values to CSV\n",
    "results_df = pd.DataFrame(\n",
    "    data = np.hstack([actuals.values, predictions]),\n",
    "    columns = [f'actual_{col}' for col in actuals.columns] + [f'pred_{col}' for col in actuals.columns],\n",
    "    index = actuals.index\n",
    ")\n",
    "results_df.to_csv('actual_vs_predicted.csv', index=True)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"R^2 Score:\", r2_score(actuals, predictions))\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(actuals, predictions))\n",
    "print(\"Root Mean Squared Error:\", root_mean_squared_error(actuals, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff15e8a2",
   "metadata": {},
   "source": [
    "## Reference site\n",
    "    지표 및 점수\n",
    "    https://scikit-learn.org/stable/modules/model_evaluation.html#model-evaluation\n",
    "    https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dh_xgboost",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
